# Simple Speech Assistant con WebSockets

Este proyecto implementa un asistente de voz basado en WebSockets que permite interactuar con un equipo de agentes mediante voz y texto. La arquitectura utiliza FastAPI para el backend y Streamlit para la interfaz de usuario, comunic치ndose a trav칠s de WebSockets para permitir respuestas en tiempo real.

## Caracter칤sticas principales

- 游꿗 **Entrada por voz**: Permite grabar mensajes de voz o subir archivos de audio
- 游댉 **Salida por voz**: Convierte las respuestas de texto a voz con gTTS
- 游눫 **Procesamiento de lenguaje natural**: Utiliza un equipo de agentes especializados para procesar consultas
- 游깷 **Arquitectura WebSocket**: Comunicaci칩n bidireccional en tiempo real
- 游 **Dise침o escalable**: Separa el frontend del backend permitiendo m칰ltiples clientes

## Arquitectura

El sistema est치 compuesto por los siguientes componentes:

![Arquitectura](https://mermaid.ink/img/pako:eNp1kMFqwzAMhl_F6JQW0iNZC4Fhi7tdmgXGdrDlxGpsF2wnI2Tv3ta1TQfbSSD9-vRLQmcMWgYnrJWnzZ0I0y2G71kSolPtHclj_r-JXP2M8fGcw0tewVuNvajM0iSp_Uu9btNi3bbrXXvImaSWPJFDYTpmIj5L6eGV9VH4YC-cFNBDuQhOqP5wYO2LwqPXFFWYlJGc19ESqeD6YIkWyODFGE0KMeWrpLXwSToZ4O8hZoJT7I4FTdQIFQyC_JCz9hCppXBxvlmZQA5KYYxuaRBnZ-BQW2RVpE2tspZhI9-vj-3-4wvu_HM1zjtjW03T9B9FcIcY)

1. **Servidor FastAPI (app.py)**:
   - Proporciona endpoints WebSocket para la comunicaci칩n en tiempo real
   - Ejecuta los agentes en procesos separados
   - Gestiona m칰ltiples conexiones de clientes

2. **Cliente Streamlit (streamlit_client.py)**:
   - Ofrece una interfaz gr치fica para el usuario
   - Graba y transcribe audio utilizando Whisper
   - Se comunica con el servidor mediante WebSockets
   - Sintetiza las respuestas en audio mediante gTTS

3. **Agentes (agents.py)**:
   - Define un equipo de agentes especializados:
     - Constructor de recetas
     - SQL Master
     - RAG Master
     - Recomendador Master
     - Team Lider
   - Utiliza modelos de Ollama para generar respuestas

4. **Agent Runner (agent_runner.py)**:
   - Script auxiliar que ejecuta los agentes en un proceso separado
   - Evita interferencias con Streamlit y FastAPI

## Requisitos previos

- Python 3.7+
- [Ollama](https://ollama.ai/) instalado y ejecut치ndose
- Modelos necesarios para Ollama:
  - llama3.2:3b
  - HridaAI/hrida-t2sql-128k

## Instalaci칩n

1. Clonar el repositorio:
```bash
git clone https://github.com/tu-usuario/simple-speech-assistant.git
cd simple-speech-assistant
```

2. Crear un entorno virtual:
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. Instalar las dependencias:
```bash
pip install -r requirements.txt
```

4. Asegurarse de tener Ollama ejecut치ndose y los modelos necesarios descargados:
```bash
# En una terminal separada
ollama serve

# En otra terminal
ollama pull llama3.2:3b
ollama pull HridaAI/hrida-t2sql-128k:latest
```

## Ejecuci칩n

### 1. Iniciar el servidor FastAPI

```bash
python app.py
```

Esto iniciar치 el servidor en `http://localhost:8000` con el endpoint WebSocket disponible en `ws://localhost:8000/ws/agent`.

### 2. Iniciar el cliente Streamlit

En otra terminal:

```bash
streamlit run streamlit_client.py
```

Esto abrir치 autom치ticamente el cliente en su navegador predeterminado (generalmente en `http://localhost:8501`).

## Uso del cliente

1. **Conectar al servidor WebSocket**:
   - En la barra lateral, aseg칰rese de que la URL del WebSocket sea correcta (`ws://localhost:8000/ws/agent`)
   - Haga clic en "Connect to WebSocket"
   - Espere a que aparezca "WebSocket Connected" en verde

2. **Cargar el modelo Whisper**:
   - Seleccione el tama침o del modelo en la barra lateral (recomendado: "base")
   - Haga clic en "Load Whisper Model"
   - Espere a que aparezca "Whisper model loaded!"

3. **Interactuar con el asistente**:
   - **Por voz**: Haga clic en el bot칩n de grabaci칩n, hable, y luego en "Process Recorded Audio"
   - **Por archivo**: Suba un archivo de audio y haga clic en "Process Uploaded File"
   - **Por texto**: Escriba su mensaje en el campo de texto y presione Enter

4. **Ver y escuchar respuestas**:
   - Las respuestas aparecer치n en la columna "Conversation Transcript"
   - Si el Text-to-Speech est치 habilitado, escuchar치 la respuesta en audio

## Caracter칤sticas avanzadas

### Configuraci칩n del idioma

- El asistente est치 configurado para trabajar en espa침ol por defecto
- Puede cambiar el idioma de la s칤ntesis de voz en la barra lateral

### Modelos Whisper

- Puede seleccionar diferentes tama침os de modelo para el reconocimiento de voz:
  - **tiny**: El m치s r치pido pero menos preciso
  - **base**: Buen equilibrio entre velocidad y precisi칩n
  - **small/medium**: M치s precisos pero requieren m치s recursos

### Personalizaci칩n de agentes

Para modificar el comportamiento de los agentes, edite el archivo `agents.py`:

```python
# Ejemplo: Cambiar el modelo utilizado por un agente
recomendador_master = Agent(
    name="Recomendador Master",
    model=Ollama(id="otro-modelo:versi칩n"),
    role="Eres un experto decorador de interiores..."
)
```

## Resoluci칩n de problemas

### Problemas de conexi칩n WebSocket

- Verifique que el servidor FastAPI est칠 ejecut치ndose
- Aseg칰rese de que la URL del WebSocket sea correcta
- Compruebe que no haya firewalls bloqueando la conexi칩n

### Errores de transcripci칩n

- Intente con un modelo Whisper m치s grande
- Aseg칰rese de que el archivo de audio tenga buena calidad
- Verifique que el modelo se haya cargado correctamente

### Problemas con los agentes

- Compruebe que Ollama est칠 ejecut치ndose
- Verifique que los modelos necesarios est칠n descargados
- Revise los logs del servidor para errores espec칤ficos

## Diagrama de secuencia

```mermaid
sequenceDiagram
    participant U as Usuario
    participant SC as Cliente Streamlit
    participant F as Servidor FastAPI
    participant A as Agentes (Ollama)
    
    U->>SC: Habla o escribe mensaje
    alt Entrada por voz
        SC->>SC: Transcribe con Whisper
    end
    SC->>F: Env칤a mensaje v칤a WebSocket
    F->>A: Ejecuta agentes
    A->>F: Devuelve respuesta
    F->>SC: Env칤a respuesta v칤a WebSocket
    SC->>SC: Convierte texto a voz (si est치 activado)
    SC->>U: Muestra y/o reproduce respuesta
```

## Notas de desarrollo

- El servidor FastAPI utiliza procesos as칤ncronos para manejar m칰ltiples conexiones
- El cliente Streamlit ejecuta el WebSocket en un hilo separado para no bloquear la interfaz
- Las respuestas de los agentes se ejecutan en procesos separados para evitar interferencias
- Se implementa cach칠 para las conversiones de texto a voz para mejorar el rendimiento